{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead81688",
   "metadata": {},
   "source": [
    "# My first RL Code\n",
    "To make the things very simple, let's create a dummy environment that gives the agent some random rewards everytime, regardless of the agent's actions.\n",
    "\n",
    "Though this is not of any practical usage, it allow us to focus on implementation of environment and agent classes.\n",
    "\n",
    "Our enviornment class should be capable of handling actions received from the agent. This is done by action method, which checks the number of steps left and returns a random reward, by ignoring the agent's action\n",
    "\n",
    "___init___ constructor is called to set the number of episodes for the event, get_observation() method is supposed to return the current environment's observation to the agent, but in this case returns a zero vector.\n",
    "\n",
    "Other methods are mostly self explanatory, get_actions returns 0 or 1 corresponding to two available actions.is_done checks the end of episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abcab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List\n",
    "\n",
    "class SampleEnvironment:\n",
    "    def __init__(self):\n",
    "        self.steps_left = 20\n",
    "\n",
    "    def get_observation(self) -> List[float]:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "\n",
    "    def get_actions(self) -> List[int]:\n",
    "        return [0, 1]\n",
    "\n",
    "    def is_done(self) -> bool:\n",
    "        return self.steps_left == 0\n",
    "\n",
    "    def action(self, action: int) -> float:\n",
    "        if self.is_done():\n",
    "            raise Exception(\"Game is over\")\n",
    "        self.steps_left -= 1\n",
    "        return random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d30aa",
   "metadata": {},
   "source": [
    "The agent's Class simple and includes only two methods: the constructor and the method that performs one step in the environment\n",
    "\n",
    "Intitially the total reward collected is set to zero by the constructor.\n",
    "\n",
    "The step function accepts environment instance as an argument and allows agent to perform the following actions:\n",
    "\n",
    "1. Observe the environment\n",
    "2. Make a decision about the action to take based on the observations\n",
    "3. Submit the action to the environment\n",
    "4. Get the reward for the current step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e28948b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74e05bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.total_reward = 0.0\n",
    "        \n",
    "    def step(self, env : SampleEnvironment):\n",
    "        current_obs = env.get_observation()\n",
    "        print(\"Observation {}\".format(current_obs))\n",
    "        actions = env.get_actions()\n",
    "        print(actions)\n",
    "        reward = env.action(random.choice(actions))\n",
    "        self.total_reward += reward\n",
    "        print(\"Total Reward {}\".format(self.total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d9340af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps 1\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 0.44886840602282607\n",
      "Steps 2\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 1.2542668456954686\n",
      "Steps 3\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 1.8016759334943449\n",
      "Steps 4\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 2.488097648699348\n",
      "Steps 5\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 2.5348045939599846\n",
      "Steps 6\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 3.294306846448272\n",
      "Steps 7\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 4.146692372747468\n",
      "Steps 8\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 4.174226357642198\n",
      "Steps 9\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 4.610062391941211\n",
      "Steps 10\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 5.5816432546212384\n",
      "Steps 11\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 6.228779483200099\n",
      "Steps 12\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 6.331676462119708\n",
      "Steps 13\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 7.117716023019194\n",
      "Steps 14\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 7.545450256807216\n",
      "Steps 15\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 7.6570606514541995\n",
      "Steps 16\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 7.787683055043251\n",
      "Steps 17\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 8.655201697537404\n",
      "Steps 18\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 9.10930299236683\n",
      "Steps 19\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 9.944486131705714\n",
      "Steps 20\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "[0, 1]\n",
      "Total Reward 9.947227856137008\n",
      "Total Reward got: 9.9472\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = SampleEnvironment()\n",
    "    agent = Agent()\n",
    "    i = 0\n",
    "    \n",
    "    while not env.is_done():\n",
    "        i = i + 1\n",
    "        print(\"Steps {}\".format(i))\n",
    "        agent.step(env)\n",
    "        \n",
    "    print(\"Total Reward got: %.4f\" %agent.total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
